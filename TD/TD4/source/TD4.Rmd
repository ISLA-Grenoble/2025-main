---
# title: "Template Work/labsheet"
# author: "Christophe Dutang, Pedro Rodrigues"
documentclass: article
papersize: a4
geometry: top=1.5cm, bottom=2cm, left=1.5cm, right=1.5cm
fontsize: 11pt
output: 
  pdf_document:
    extra_dependencies: ["enumitem"]
    number_sections: true
    toc: false
    keep_tex: false
    includes:
      in_header: "TD4-preamble.tex"
      before_body: "TD4-header.tex"
      
---

<!-- see help at https://bookdown.org/yihui/rmarkdown-cookbook/latex-output.html -->

```{r setup, include=FALSE, message=FALSE}
#see full list >knitr::opts_chunk$get()
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
library(reticulate)
use_python("/opt/homebrew/Caskroom/miniforge/base/envs/isla2025/bin/python", required = T)
```

\section*{$\blacktriangleright$~Quick review of PCA}

\section*{$\blacktriangleright$~Exercise 1 (credits to Berkeley  CS-189)}
In linear regression, we model $p(y \mid \mathbf{x}) \sim \mathcal{N}(\beta^\top \mathbf{x} + \beta_0, \sigma^2)$. The irreducible error in this model is
\begin{itemize}
\item[(A)] $\sigma^2$
\item[(B)] $\mathbb{E}[y \mid \mathbf{x}]$
\item[(C)] $\mathbb{E}[(y - \mathbb{E}[y \mid \mathbf{x}])^2 \mid \mathbf{x}]$
\item[(D)] None of the above.
\end{itemize}

\section*{$\blacktriangleright$~Exercise 2 (credits to EPFL CS-433)}
Which of the following transformations to a data matrix $\mathbf{X}$ will affect the principal components obtained through PCA?
\begin{itemize}
 \renewcommand{\labelitemi}{\scriptsize$\square$}
\item[(A)] Adding a constant value to all elements of $\mathbf{X}$.
\item[(B)] Multiplying one of the features of $\mathbf{X}$ by a constant.
\item[(C)] Adding an extra feature to $\mathbf{X}$ (i.e. an extra column) that is constant across all data points.
\item[(D)] None of the above answers.
\end{itemize}

\section*{$\blacktriangleright$~Exercise 3}
In this exercise, we will use the results from a survey performed in the 1950s in France. The dataset contains the average number of Francs spent on several categories of food products according to social class and the number of children per family. We display below some of the rows and columns of this dataset.

```{python}
import pandas as pd
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

df = pd.read_csv('foodFrance.csv', index_col=0)
print(df)
```

\begin{enumerate}
\item[(a)] Given how the dataset is defined, if we were to do a PCA, would it be preferable to scale or not the variables? Explain your reasoning.
\item[(b)] The plots below illustrate the results of the PCA carried out on the dataset. Interpret what information each principal axis convey and how it is related to the different social classes for each data point. Note that the acronyms on the right panel indicate the social class and the number of children, for instance: \code{WC4} means ``White collar with 4 children''.
\end{enumerate} 

```{python, echo=FALSE, results='hide'}
X = df.values[:, 2:].astype(np.float64)
acronyms = ['BC2', 'WC2', 'UC2', 'BC3', 'WC3', 'UC3', 'BC4', 'WC4', 'UC4', 'BC5', 'WC5', 'UC5']

pca = PCA(n_components=2)
Xpca = pca.fit_transform(X)

df_pc = pd.DataFrame()
df_pc['PC1'] = pca.components_[0, :]
df_pc['PC2'] = pca.components_[1, :]
df_pc.index = df.columns[2:]

fig, axs = plt.subplots(figsize=(12.0, 5.5), ncols=2)

ax = axs[0]
circle = plt.Circle((0, 0), 1, color='C0', lw=2.0, fill=False)
ax.add_patch(circle)
std_y = pca.singular_values_ / np.sqrt(len(df))
std_x = np.std(X, axis=0)
points = df_pc.multiply(std_y, axis=1).divide(std_x, axis=0).values
for i, pi in enumerate(points):
    # ax.scatter(pi[0], pi[1], s=120, edgecolor='k', facecolor='none')
    ax.scatter(pi[0], pi[1], s=120, color='C3')
ax.text(points[0][0] - 0.35, points[0][1] - 0.01, 'Bread', size=14)   
ax.text(points[1][0] - 0.60, points[1][1], 'Vegetables', size=14)   
ax.text(points[2][0] - 0.32, points[2][1], 'Fruits', size=14)   
ax.text(points[3][0] - 0.30, points[3][1] + 0.07, 'Meat', size=14)   
ax.text(points[4][0] - 0.35, points[4][1] - 0.10, 'Poultry', size=14)   
ax.text(points[5][0] - 0.02, points[5][1] - 0.14, 'Milk', size=14)   
ax.text(points[6][0] + 0.05, points[6][1] + 0.03, 'Wine', size=14)   
ax.axvline(x=0, c='k', lw=0.8)
ax.axhline(y=0, c='k', lw=0.8)
ax.set_xlim(-1.05, +1.05)
ax.set_ylim(-1.05, +1.05)
ax.set_title('Variable space')

ax = axs[1]
colors = {'Blue collar': 'b', 'White collar': 'g', 'Upper class': 'r'}
for socialclass in colors.keys():
    idx = (df['Class'] == socialclass)
    ax.scatter(Xpca[idx, 0], Xpca[idx, 1], s=100, c=colors[socialclass])
for i, Xi in enumerate(Xpca):
    ax.text(Xi[0] + 15, Xi[1] + 10, s=acronyms[i], size=14)
ax.axvline(x=0, c='k', lw=0.8)
ax.axhline(y=0, c='k', lw=0.8)
ax.set_xlim(-720, 1250)
ax.set_ylim(-250, 320)
ax.set_xlabel('PC1')
ax.set_ylabel('PC2')
ax.set_title('Data space')

fig.show()
```

\section*{$\blacktriangleright$~Questions from previous classes and TP1}
